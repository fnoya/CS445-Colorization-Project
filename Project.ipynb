{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd0297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from fastai.vision.learner import create_body\n",
    "from torchvision.models.resnet import resnet18\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_colab = None\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    " from fastai.data.external import untar_data, URLs\n",
    " coco_path = untar_data(URLs.COCO_SAMPLE)\n",
    " coco_path = str(coco_path) + \"/train_sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = coco_path\n",
    "\n",
    "    \n",
    "paths = glob.glob(path + \"/*.jpg\") # Grabbing all the image file names\n",
    "np.random.seed(123)\n",
    "paths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 1000 images randomly\n",
    "rand_idxs = np.random.permutation(10_000)\n",
    "train_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\n",
    "val_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\n",
    "train_paths = paths_subset[train_idxs]\n",
    "val_paths = paths_subset[val_idxs]\n",
    "print(len(train_paths), len(val_paths))\n",
    "\n",
    "_, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for ax, img_path in zip(axes.flatten(), train_paths):\n",
    "    ax.imshow(Image.open(img_path))\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(), # A little data augmentation!\n",
    "            ])\n",
    "        elif split == 'val':\n",
    "            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
    "        \n",
    "        self.split = split\n",
    "        self.size = SIZE\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n",
    "        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n",
    "        \n",
    "        return {'L': L, 'ab': ab}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, **kwargs): # A handy function to make our dataloaders\n",
    "    dataset = ColorizationDataset(**kwargs)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                            pin_memory=pin_memory)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = make_dataloaders(paths=train_paths, split='train')\n",
    "val_dl = make_dataloaders(paths=val_paths, split='val')\n",
    "\n",
    "data = next(iter(train_dl))\n",
    "Ls, abs_ = data['L'], data['ab']\n",
    "print(Ls.shape, abs_.shape)\n",
    "print(len(train_dl), len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n",
    "                          for i in range(n_down)] # the 'if' statement is taking care of not using\n",
    "                                                  # stride of 2 for the last block in this loop\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n",
    "                                                                                             # activation for the last layer of the model\n",
    "        self.model = nn.Sequential(*model)                                                   \n",
    "        \n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss()\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "    \n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "    \n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ceff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init='norm', gain=0.02):\n",
    "    \n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            \n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "            \n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialized with {init} initialization\")\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, \n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        if net_G is None:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "    \n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.fake_color = self.net_G(self.L)\n",
    "    \n",
    "    def backward_D(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "        \n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94161614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "    \n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def create_loss_meters():\n",
    "    loss_D_fake = AverageMeter()\n",
    "    loss_D_real = AverageMeter()\n",
    "    loss_D = AverageMeter()\n",
    "    loss_G_GAN = AverageMeter()\n",
    "    loss_G_L1 = AverageMeter()\n",
    "    loss_G = AverageMeter()\n",
    "    \n",
    "    return {'loss_D_fake': loss_D_fake,\n",
    "            'loss_D_real': loss_D_real,\n",
    "            'loss_D': loss_D,\n",
    "            'loss_G_GAN': loss_G_GAN,\n",
    "            'loss_G_L1': loss_G_L1,\n",
    "            'loss_G': loss_G}\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    Takes a batch of images\n",
    "    \"\"\"\n",
    "    \n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0)\n",
    "    \n",
    "def visualize(model, data, save=True):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    real_imgs = lab_to_rgb(L, real_color)\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real_imgs[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"output/colorization_{time.time()}.png\")\n",
    "    return fake_imgs, real_imgs\n",
    "        \n",
    "def log_results(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, epochs, display_every=200, first_epoch=0):\n",
    "    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intrvals\n",
    "    for e in range(first_epoch, epochs):\n",
    "        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to \n",
    "        i = 0                                  # log the losses of the complete network\n",
    "        for data in tqdm(train_dl):\n",
    "            model.setup_input(data) \n",
    "            model.optimize()\n",
    "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n",
    "            i += 1\n",
    "            if i % display_every == 0:\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
    "                log_results(loss_meter_dict) # function to print out the losses\n",
    "                visualize(model, data, save=False) # function displaying the model's outputs\n",
    "        torch.save(model.state_dict(), 'models/model2-' + str(e+1) +'.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a990cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_res_unet(n_input=1, n_output=2, size=256):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n",
    "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
    "    return net_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7775f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n",
    "    for e in range(epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        for data in tqdm(train_dl):\n",
    "            L, ab = data['L'].to(device), data['ab'].to(device)\n",
    "            preds = net_G(L)\n",
    "            loss = criterion(preds, ab)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            loss_meter.update(loss.item(), L.size(0))\n",
    "            \n",
    "        print(f\"Epoch {e + 1}/{epochs}\")\n",
    "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n",
    "        #torch.save(net_G.state_dict(), 'models/net_G_resnet18_model-' + str(e) +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cafbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MainModel()\n",
    "model.load_state_dict(torch.load('models/model-012.pt'))\n",
    "#train_model(model, train_dl, 100)\n",
    "train_model(model, train_dl, 100, first_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
    "opt = optim.Adam(net_G.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()        \n",
    "pretrain_generator(net_G, train_dl, opt, criterion, 20)\n",
    "torch.save(net_G.state_dict(), \"models/net_G_resnet18_model-19.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae380ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
    "net_G.load_state_dict(torch.load(\"models/net_G_resnet18_model-19.pt\", map_location=device))\n",
    "model = MainModel(net_G=net_G)\n",
    "train_model(model, train_dl, 20)\n",
    "torch.save(net_G.state_dict(), \"models/colorization2-epoch20.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09044ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
    "# net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n",
    "model = MainModel(net_G=net_G)\n",
    "model.load_state_dict(torch.load(\"models/colorization2-epoch20.pt\", map_location=device))\n",
    "test_paths = glob.glob(\"images/*.JPG\")\n",
    "\n",
    "test_dl = make_dataloaders(paths=test_paths, split='val',  n_workers=0)  ## n_workers=0 in Windows\n",
    "test_iter = iter(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81409235",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(test_iter)\n",
    "fake_imgs, real_imgs = visualize(model, data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40137375",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "\n",
    "img = fake_imgs[i]\n",
    "rimg = real_imgs[i]\n",
    "plt.imshow(img),plt.show(),plt.imshow(rimg),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49935b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc666290",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce030051",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "mask_coords = utils.specify_mask(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f454772",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = mask_coords[0]\n",
    "ys = mask_coords[1]\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "fg_mask = utils.get_mask(ys, xs, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a06f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "bgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "fg_mask[fg_mask==1] = cv2.GC_PR_FGD\n",
    "img = np.uint8(img*255)\n",
    "fg_mask = np.uint8(fg_mask)\n",
    "(mask, bgModel, fgModel) = cv2.grabCut(img, fg_mask, None, bgModel, \\\n",
    "                                       fgModel, iterCount=5, mode=cv2.GC_INIT_WITH_MASK)\n",
    "\n",
    "mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "fg_img = img*mask[:,:,np.newaxis]\n",
    "plt.imshow(fg_img),plt.colorbar(),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), cv2.COLOR_GRAY2RGB) \n",
    "mask = mask[:,:,np.newaxis]\n",
    "final_img = img_gray * (1 - mask) + fg_img * mask\n",
    "plt.imshow(final_img),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432592be",
   "metadata": {},
   "source": [
    " ## References\n",
    " \n",
    " * https://pyimagesearch.com/2020/07/27/opencv-grabcut-foreground-segmentation-and-extraction/\n",
    " * https://docs.opencv.org/3.4/d8/d83/tutorial_py_grabcut.html\n",
    " * https://towardsdatascience.com/colorizing-black-white-images-with-u-net-and-conditional-gan-a-tutorial-81b2df111cd8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2f2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
